{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "90654c93",
      "metadata": {
        "id": "90654c93"
      },
      "source": [
        "\n",
        "# NLP Tutorial — Part 6: Topic Modeling Algorithms\n",
        "\n",
        "**Runtime:** Google Colab (recommended)\n",
        "\n",
        "In this notebook, you'll learn and *compare* several topic modeling approaches:\n",
        "\n",
        "1. **Vectorizing text** (Count & TF-IDF)\n",
        "2. **Non-negative Matrix Factorization (NMF)** — great for *small* datasets, interpretable (scikit-learn)\n",
        "3. **Latent Dirichlet Allocation (LDA)** — probabilistic model, works better on *medium* datasets (Gensim)\n",
        "4. **Modern embedding-based methods** — great for *larger* datasets:\n",
        "   - **BERTopic**\n",
        "   - **Top2Vec**\n",
        "\n",
        "> **Choice guidance**\n",
        "> - **Small dataset:** Start with **NMF**.\n",
        "> - **Medium dataset:** Try **LDA**.\n",
        "> - **Large dataset / modern stack:** Try **BERTopic** or **Top2Vec** (embedding-based).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "57822163",
      "metadata": {
        "id": "57822163"
      },
      "source": [
        "\n",
        "## 0) Setup & Installs\n",
        "\n",
        "> 🧰 Run this cell first in Colab. It installs libraries you may not have locally.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4292e7d8",
      "metadata": {
        "id": "4292e7d8"
      },
      "outputs": [],
      "source": [
        "# Core\n",
        "%pip -q install scikit-learn pandas numpy matplotlib\n",
        "\n",
        "# Topic modeling libraries\n",
        "%pip -q install gensim pyLDAvis==3.4.1\n",
        "\n",
        "# Embeddings + modern topic models\n",
        "%pip -q install sentence-transformers umap-learn hdbscan\n",
        "%pip -q install bertopic\n",
        "%pip -q install top2vec\n",
        "%pip -q install gensim==4.3.3\n",
        "\n",
        "print(\"✅ Installs complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bbae17e",
      "metadata": {
        "id": "7bbae17e"
      },
      "source": [
        "\n",
        "## 1) Load a Dataset\n",
        "\n",
        "We'll default to a manageable subset of **20 Newsgroups**.  \n",
        "You can also bring your own data — a CSV with a `text` column — using the provided template.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55426927",
      "metadata": {
        "id": "55426927"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "# --- Option A: Use 20 Newsgroups (subset for speed) ---\n",
        "categories = [\n",
        "    'sci.space', 'comp.graphics', 'rec.sport.baseball',\n",
        "    'talk.politics.mideast', 'sci.med'\n",
        "]\n",
        "\n",
        "newsgroups = fetch_20newsgroups(subset='train', categories=categories, remove=('headers','quotes','footers'))\n",
        "texts = newsgroups.data\n",
        "targets = newsgroups.target\n",
        "target_names = newsgroups.target_names\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"text\": texts,\n",
        "    \"label\": [target_names[t] for t in targets]\n",
        "})\n",
        "\n",
        "print(df.shape)\n",
        "df.head(3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60f6ea69",
      "metadata": {
        "id": "60f6ea69"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- Option B: Load your own CSV (expects a 'text' column) ---\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()  # then set filename below\n",
        "# df = pd.read_csv(\"your_file.csv\")\n",
        "# assert 'text' in df.columns, \"Your CSV must contain a 'text' column\"\n",
        "# df = df.dropna(subset=['text']).reset_index(drop=True)\n",
        "# df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03222639",
      "metadata": {
        "id": "03222639"
      },
      "source": [
        "\n",
        "## 2) Preprocessing & Vectorization\n",
        "\n",
        "We demonstrate both **CountVectorizer** and **TfidfVectorizer**.  \n",
        "You'll choose which to feed into a topic model depending on the algorithm and your goals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10f14eaa",
      "metadata": {
        "id": "10f14eaa"
      },
      "outputs": [],
      "source": [
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def simple_clean(text):\n",
        "    # light cleaning to keep the tutorial focused on modeling\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    text = re.sub(r\"http\\S+\", \" \", text)  # drop URLs\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "df['clean_text'] = df['text'].apply(simple_clean)\n",
        "df = df[df['clean_text'].str.len() > 0].reset_index(drop=True)\n",
        "len(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b40d1200",
      "metadata": {
        "id": "b40d1200"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "# You can tweak min_df, max_df, ngram_range to balance specificity vs generality\n",
        "count_vectorizer = CountVectorizer(\n",
        "    max_features=20000,\n",
        "    min_df=2,\n",
        "    max_df=0.9,\n",
        "    ngram_range=(1,2),\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(\n",
        "    max_features=20000,\n",
        "    min_df=2,\n",
        "    max_df=0.9,\n",
        "    ngram_range=(1,2),\n",
        "    stop_words='english'\n",
        ")\n",
        "\n",
        "X_count = count_vectorizer.fit_transform(df['clean_text'])\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(df['clean_text'])\n",
        "\n",
        "X_count.shape, X_tfidf.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f4c6d9d",
      "metadata": {
        "id": "7f4c6d9d"
      },
      "source": [
        "\n",
        "> **Rule of thumb**\n",
        "> - **NMF** usually does well with **TF-IDF** features.\n",
        "> - **LDA** is a probabilistic model over **raw counts** (bag-of-words).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70f09e53",
      "metadata": {
        "id": "70f09e53"
      },
      "source": [
        "\n",
        "## 3) Non-negative Matrix Factorization (NMF) — Small Datasets\n",
        "\n",
        "- Library: **scikit-learn**  \n",
        "- Inputs: Prefer **TF-IDF**  \n",
        "- Strengths: Often yields **interpretable** topics for small corpora\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1660929",
      "metadata": {
        "id": "b1660929"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.decomposition import NMF\n",
        "\n",
        "n_topics = 10  # adjust\n",
        "nmf = NMF(n_components=n_topics, random_state=42, init='nndsvda', max_iter=400)\n",
        "W = nmf.fit_transform(X_tfidf)  # doc-topic matrix\n",
        "H = nmf.components_               # topic-term matrix\n",
        "\n",
        "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "def show_top_terms(H, feature_names, topn=12):\n",
        "    topics = []\n",
        "    for idx, topic_vec in enumerate(H):\n",
        "        top_idx = topic_vec.argsort()[::-1][:topn]\n",
        "        terms = [feature_names[i] for i in top_idx]\n",
        "        topics.append((idx, terms))\n",
        "    return topics\n",
        "\n",
        "topics_nmf = show_top_terms(H, feature_names, topn=12)\n",
        "for k, terms in topics_nmf:\n",
        "    print(f\"Topic {k:02d}: \" + \", \".join(terms))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c6684c9",
      "metadata": {
        "id": "2c6684c9"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Inspect top documents per topic\n",
        "import numpy as np\n",
        "\n",
        "def top_docs_for_topic(W, docs, topic_id, topn=5):\n",
        "    scores = W[:, topic_id]\n",
        "    idx = np.argsort(scores)[::-1][:topn]\n",
        "    return [(i, float(scores[i]), docs[i][:300].replace(\"\\n\",\" \")) for i in idx]\n",
        "\n",
        "topic_id = 0\n",
        "top_docs = top_docs_for_topic(W, df['clean_text'].tolist(), topic_id, topn=3)\n",
        "for i, score, snippet in top_docs:\n",
        "    print(f\"Doc {i} — score={score:.3f}\\n{snippet}\\n{'-'*80}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db0ce5ba",
      "metadata": {
        "id": "db0ce5ba"
      },
      "source": [
        "\n",
        "> **Tuning tips for NMF**\n",
        "> - Increase/decrease `n_components` to adjust granularity.\n",
        "> - Filter very common/rare terms via `max_df`, `min_df`.\n",
        "> - Try different `ngram_range` values (e.g., `(1,1)` vs `(1,2)`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b2279ee",
      "metadata": {
        "id": "1b2279ee"
      },
      "source": [
        "\n",
        "## 4) Latent Dirichlet Allocation (LDA) — Medium Datasets\n",
        "\n",
        "- Library: **Gensim**  \n",
        "- Inputs: **Count (bag-of-words)**  \n",
        "- Strengths: Probabilistic; often better than NMF on medium-sized corpora  \n",
        "- Randomness is involved; set seeds for reproducibility where possible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b40d169e",
      "metadata": {
        "id": "b40d169e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "# Build Gensim dictionary + BOW corpus from tokenized text used by CountVectorizer\n",
        "# We'll reuse the CountVectorizer's vocabulary to keep things aligned.\n",
        "inv_vocab = {v:k for k,v in count_vectorizer.vocabulary_.items()}\n",
        "\n",
        "def to_bow(row, X_sparse):\n",
        "    # Convert a single row of the sparse matrix to Gensim BOW using the same vocabulary indices\n",
        "    cols = X_sparse[row].nonzero()[1]\n",
        "    counts = X_sparse[row, cols].toarray().ravel()\n",
        "    # Map col indices back to tokens\n",
        "    tokens = [inv_vocab[c] for c in cols]\n",
        "    # Build dictionary on the fly is expensive; better to prebuild\n",
        "    return list(zip(tokens, counts))\n",
        "\n",
        "# Build a consistent Gensim dictionary\n",
        "tokens_list = []\n",
        "for i in range(X_count.shape[0]):\n",
        "    cols = X_count[i].nonzero()[1]\n",
        "    tokens_list.append([inv_vocab[c] for c in cols])\n",
        "\n",
        "dictionary = corpora.Dictionary(tokens_list)\n",
        "bow_corpus = [dictionary.doc2bow(tokens) for tokens in tokens_list]\n",
        "\n",
        "# Train LDA\n",
        "num_topics = 10\n",
        "lda_model = gensim.models.LdaModel(\n",
        "    corpus=bow_corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=num_topics,\n",
        "    random_state=42,\n",
        "    chunksize=2000,\n",
        "    passes=5,\n",
        "    alpha='auto',\n",
        "    eta='auto',\n",
        "    per_word_topics=False\n",
        ")\n",
        "\n",
        "for i, topic in lda_model.show_topics(num_topics=num_topics, num_words=12, formatted=False):\n",
        "    terms = \", \".join([w for w,_ in topic])\n",
        "    print(f\"Topic {i:02d}: {terms}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "112e9bb0",
      "metadata": {
        "id": "112e9bb0"
      },
      "outputs": [],
      "source": [
        "# Optional: Interactive visualization with pyLDAvis (works in Colab)\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "lda_vis = gensimvis.prepare(lda_model, bow_corpus, dictionary)\n",
        "lda_vis  # In Colab: this should render an interactive panel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fe5df87",
      "metadata": {
        "id": "1fe5df87"
      },
      "source": [
        "\n",
        "> **Tuning tips for LDA**\n",
        "> - Try `passes` and `iterations` (more can improve stability, but costs time).\n",
        "> - Start with 5–20 topics; refine as needed.\n",
        "> - Consider lemmatization and custom stop-word lists for domain data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d361d4f4",
      "metadata": {
        "id": "d361d4f4"
      },
      "source": [
        "\n",
        "## 5) BERTopic — Embedding-based Topic Modeling (Modern, Larger Datasets)\n",
        "\n",
        "- Uses transformer embeddings + clustering to form topics.\n",
        "- Often more robust for varied language use and larger corpora.\n",
        "- Library: **BERTopic** (depends on `sentence-transformers`, `umap-learn`, `hdbscan`).\n",
        "\n",
        "> ⚠️ If this cell is slow on CPU, switch to **GPU** in Colab (Runtime → Change runtime type → T4 GPU).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3d75f186",
      "metadata": {
        "id": "3d75f186"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from umap import UMAP  # or: from umap.umap_ import UMAP\n",
        "\n",
        "# small, fast embedder\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# make results reproducible via UMAP's random_state\n",
        "umap_model = UMAP(\n",
        "    n_neighbors=15,\n",
        "    n_components=5,\n",
        "    min_dist=0.0,\n",
        "    metric=\"cosine\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=embed_model,\n",
        "    umap_model=umap_model,\n",
        "    verbose=True,\n",
        "    calculate_probabilities=True,\n",
        "    min_topic_size=10\n",
        ")\n",
        "\n",
        "texts_for_bertopic = df[\"clean_text\"].tolist()\n",
        "topics, probs = topic_model.fit_transform(texts_for_bertopic)\n",
        "\n",
        "topic_info = topic_model.get_topic_info()\n",
        "topic_info.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c730928",
      "metadata": {
        "id": "1c730928"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Show top terms per topic\n",
        "for topic_id in topic_info['Topic'].head(10):\n",
        "    if topic_id == -1:\n",
        "        continue  # -1 is usually outliers\n",
        "    print(f\"Topic {topic_id}:\")\n",
        "    print(topic_model.get_topic(topic_id))\n",
        "    print(\"-\"*80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b7b556d",
      "metadata": {
        "id": "2b7b556d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Optional interactive visualizations (Plotly)\n",
        "try:\n",
        "    fig = topic_model.visualize_barchart(top_n_topics=10)\n",
        "    fig.show()\n",
        "except Exception as e:\n",
        "    print(\"Visualization skipped:\", e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ce2c103",
      "metadata": {
        "id": "2ce2c103"
      },
      "source": [
        "\n",
        "## 6) Top2Vec — Embedding + Joint Topic Discovery\n",
        "\n",
        "- Learns document embeddings and discovers topics without predefined `k`.\n",
        "- Can be heavier than BERTopic depending on embedding choice; keep dataset modest in demos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5a350cf",
      "metadata": {
        "id": "a5a350cf"
      },
      "outputs": [],
      "source": [
        "from top2vec import Top2Vec\n",
        "\n",
        "docs_small = df['clean_text'].tolist()[:1500]\n",
        "\n",
        "t2v = Top2Vec(\n",
        "    documents=docs_small,\n",
        "    embedding_model='doc2vec',   # or 'universal-sentence-encoder', 'distiluse-base-multilingual-cased'\n",
        "    speed='learn',\n",
        "    workers=4,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# get the total and then fetch them\n",
        "num_topics = t2v.get_num_topics()\n",
        "topic_words, word_scores, topic_nums = t2v.get_topics(num_topics)\n",
        "\n",
        "print(\"Discovered topics:\", len(topic_nums))\n",
        "for i in range(min(10, len(topic_nums))):\n",
        "    terms = \", \".join(topic_words[i][:12])\n",
        "    print(f\"Topic {topic_nums[i]}: {terms}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456e6644",
      "metadata": {
        "id": "456e6644"
      },
      "source": [
        "\n",
        "## 7) Evaluation & Model Selection\n",
        "\n",
        "There isn't a single perfect metric for topic modeling, but you can use a mix of:\n",
        "\n",
        "- **Coherence** (e.g., `c_v`, `u_mass`) — correlates with human interpretability.\n",
        "- **Diversity** — share of unique tokens among top words across topics.\n",
        "- **Human-in-the-loop** — have domain experts label topics or rate quality.\n",
        "- **Downstream utility** — e.g., topic features improve a classifier or retrieval task.\n",
        "\n",
        "Below are simple examples for *coherence* (Gensim) and *diversity*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e267129",
      "metadata": {
        "id": "3e267129"
      },
      "outputs": [],
      "source": [
        "from gensim.corpora import Dictionary\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "def nmf_topics_as_terms(H, feature_names, topn=10):\n",
        "    topics = []\n",
        "    for topic_vec in H:\n",
        "        top_idx = topic_vec.argsort()[::-1][:topn]\n",
        "        topics.append([feature_names[i] for i in top_idx])\n",
        "    return topics\n",
        "\n",
        "# 1) Prepare topics from NMF and a dictionary from your tokenized docs\n",
        "nmf_term_lists = nmf_topics_as_terms(H, feature_names, topn=10)\n",
        "\n",
        "tokens_for_eval = tokens_list  # list[list[str]] of tokens per doc (no empty docs)\n",
        "\n",
        "dictionary = Dictionary(tokens_for_eval)\n",
        "# optional but recommended: trim extremes to reduce noise\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.5, keep_n=50000)\n",
        "\n",
        "# 2) Compute c_v coherence (uses texts + dictionary)\n",
        "coh_nmf = CoherenceModel(\n",
        "    topics=nmf_term_lists,\n",
        "    texts=tokens_for_eval,\n",
        "    dictionary=dictionary,\n",
        "    coherence='c_v'\n",
        ").get_coherence()\n",
        "\n",
        "print(f\"NMF c_v coherence: {coh_nmf:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723f72a3",
      "metadata": {
        "id": "723f72a3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Topic diversity (unique top terms across topics)\n",
        "def topic_diversity(topic_term_lists):\n",
        "    all_terms = [term for topic in topic_term_lists for term in topic]\n",
        "    unique_terms = len(set(all_terms))\n",
        "    total_terms = len(all_terms)\n",
        "    return unique_terms / total_terms if total_terms else 0.0\n",
        "\n",
        "div_nmf = topic_diversity(nmf_term_lists)\n",
        "print(f\"NMF topic diversity (top-10 terms): {div_nmf:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c6e3ced",
      "metadata": {
        "id": "2c6e3ced"
      },
      "source": [
        "\n",
        "## 8) Using Your Own Data\n",
        "\n",
        "1. Upload a CSV with a `text` column.\n",
        "2. Re-run **Section 1 (Option B)** and **Section 2**.\n",
        "3. Choose **one** modeling approach (Sections 3–6) and tune hyperparameters:\n",
        "   - Topic count (`n_components` for NMF, `num_topics` for LDA)\n",
        "   - Vectorizer settings (`min_df`, `max_df`, `ngram_range`)\n",
        "   - Clustering & dimensionality reduction settings for BERTopic/Top2Vec\n",
        "4. Evaluate with **Section 7**, iterate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aac8a42b",
      "metadata": {
        "id": "aac8a42b"
      },
      "source": [
        "\n",
        "## 9) Practical Tips & Gotchas\n",
        "\n",
        "- **Preprocessing matters**: custom stopwords, lemmatization, phrase detection (bigrams) can help.\n",
        "- **Interpretability vs. coherence**: pick settings that produce topics you (and stakeholders) find useful.\n",
        "- **Reproducibility**: fix random seeds where possible; document versions and parameters.\n",
        "- **Performance**: for large corpora, prefer GPU runtime and smaller embedding models initially.\n",
        "- **Ethics**: inspect topics for bias or privacy leaks before sharing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "648ccd61",
      "metadata": {
        "id": "648ccd61"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "### Credits & References\n",
        "- scikit-learn: NMF, vectorizers\n",
        "- Gensim: LDA, coherence, pyLDAvis integration\n",
        "- BERTopic: https://github.com/MaartenGr/BERTopic\n",
        "- Top2Vec: https://github.com/ddangelov/Top2Vec\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}